{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "8nS9myTh3oXv",
        "outputId": "867c70ef-57c5-4586-d254-85db784dc59b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/Lab Session02 Data.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-96445d521b99>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m# Load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Lab Session02 Data.xlsx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Purchase Data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0mdf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Lab Session02 Data.xlsx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"thyroid0387_UCI\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-96445d521b99>\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(file_path, sheet_name)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;34m\"\"\"Load dataset from Excel file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_stock_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Lab Session02 Data.xlsx'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "\n",
        "def load_dataset(file_path, sheet_name=None):\n",
        "    \"\"\"Load dataset from Excel file.\"\"\"\n",
        "    return pd.read_excel(file_path, sheet_name=sheet_name)\n",
        "\n",
        "def segregate_data(data):\n",
        "    # Segregate the data into matrices A and C.\n",
        "    A = np.matrix(data[[\"Candies (#)\", \"Mangoes (Kg)\", \"Milk Packets (#)\"]])\n",
        "    C = np.matrix(data[[\"Payment (Rs)\"]])\n",
        "    return A, C\n",
        "\n",
        "def calculate_dimensions(A, C):\n",
        "    # Print dimensions of matrices A and C.\n",
        "    return np.shape(A), np.shape(C)\n",
        "\n",
        "\n",
        "def calculate_rank(A):\n",
        "    # Calculate and return the rank of matrix A.\n",
        "    return np.linalg.matrix_rank(A)\n",
        "\n",
        "def calculate_pseudo_inverse(A):\n",
        "    # Calculate the pseudo-inverse of matrix A\n",
        "    return np.linalg.pinv(A)\n",
        "\n",
        "def calculate_model_vector(x_pseudo_inv, C):\n",
        "    # Calculate the model vector X using pseudo-inverse.\n",
        "    return np.dot(x_pseudo_inv, C)\n",
        "\n",
        "def RichPoorClassifier(data):\n",
        "    # Classify customers as 'RICH' or 'POOR'.\n",
        "    classes = []\n",
        "    for cost in data[\"Payment (Rs)\"]:\n",
        "        if cost > 200:\n",
        "            classes.append(\"RICH\")\n",
        "        else:\n",
        "            classes.append(\"POOR\")\n",
        "    return classes\n",
        "\n",
        "def preprocess_stock_data(df):\n",
        "    \"\"\"Preprocess stock data by setting index and cleaning percentage column.\"\"\"\n",
        "    df[\"Chg%\"] = df[\"Chg%\"].astype(str).str.replace(\"%\", \"\").astype(float)\n",
        "    return df\n",
        "\n",
        "def add_class_to_data(data, classes):\n",
        "    # Add the 'Class' column to the DataFrame.\n",
        "    data[\"Class\"] = classes\n",
        "    return data\n",
        "\n",
        "def calculate_mean(df, column):\n",
        "    \"\"\"Calculate mean of a numerical column.\"\"\"\n",
        "    return statistics.mean(df[column].dropna())\n",
        "\n",
        "def calculate_variance(df, column):\n",
        "    \"\"\"Calculate variance of a numerical column.\"\"\"\n",
        "    return statistics.variance(df[column].dropna())\n",
        "\n",
        "def mean_price_on_wednesday(df):\n",
        "    \"\"\"Calculate mean price on Wednesdays.\"\"\"\n",
        "    price_on_wed = df[df[\"Day\"] == \"Wed\"][\"Price\"]\n",
        "    return statistics.mean(price_on_wed)\n",
        "\n",
        "def mean_price_in_month(df, month):\n",
        "    \"\"\"Calculate mean price for a specific month.\"\"\"\n",
        "    price_month = df[df[\"Month\"] == month][\"Price\"]\n",
        "    return statistics.mean(price_month)\n",
        "\n",
        "def probability_of_loss(df):\n",
        "    \"\"\"Calculate probability of making a loss.\"\"\"\n",
        "    neg_chg = df[df[\"Chg%\"] < 0]\n",
        "    return len(neg_chg) / len(df)\n",
        "\n",
        "def probability_of_profit_on_wednesday(df):\n",
        "    \"\"\"Calculate probability of making a profit on a Wednesday.\"\"\"\n",
        "    Wednesdays = df[df[\"Day\"] == \"Wed\"]\n",
        "    if len(Wednesdays) == 0:\n",
        "        return 0\n",
        "    profitable_Wednesdays = Wednesdays[Wednesdays[\"Chg%\"] > 0]\n",
        "    return len(profitable_Wednesdays) / len(Wednesdays)\n",
        "\n",
        "def plot_chg_vs_day(df):\n",
        "    \"\"\"Plot Change% vs Day of the week.\"\"\"\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.scatter(df[\"Day\"], df[\"Chg%\"], color=\"blue\", alpha=0.6)\n",
        "    plt.title(\"Chg% vs Day of the Week\")\n",
        "    plt.xlabel(\"Day of the Week\")\n",
        "    plt.ylabel(\"Chg%\")\n",
        "    plt.show()\n",
        "\n",
        "def identify_columns(data):\n",
        "    \"\"\"Identify categorical and numerical columns.\"\"\"\n",
        "    categorical_cols = [col for col in data.columns if data[col].dtype == 'object']\n",
        "    numerical_cols = [col for col in data.columns if data[col].dtype != 'object']\n",
        "    return categorical_cols, numerical_cols\n",
        "\n",
        "def encode_categorical_data(data, categorical_cols):\n",
        "    \"\"\"Encode categorical columns using Label Encoding or One-Hot Encoding.\"\"\"\n",
        "    encoded_data = data.copy()\n",
        "    label_encoders = {}\n",
        "    one_hot_columns = []\n",
        "\n",
        "    for col in categorical_cols:\n",
        "        unique_values = data[col].unique()\n",
        "        if len(unique_values) <= 5:\n",
        "            le = LabelEncoder()\n",
        "            encoded_data[col] = le.fit_transform(data[col])\n",
        "            label_encoders[col] = le\n",
        "        else:\n",
        "            one_hot_columns.append(col)\n",
        "\n",
        "    encoded_data = pd.get_dummies(encoded_data, columns=one_hot_columns)\n",
        "    return encoded_data, label_encoders\n",
        "\n",
        "def check_missing_values(data):\n",
        "    \"\"\"Check for missing values in the dataset.\"\"\"\n",
        "    return {col: data[col].isnull().sum() for col in data.columns if data[col].isnull().sum() > 0}\n",
        "\n",
        "def normalize_data(data, numerical_cols):\n",
        "    \"\"\"Normalize numerical columns using Min-Max Scaling.\"\"\"\n",
        "    scaler = MinMaxScaler()\n",
        "    data[numerical_cols] = scaler.fit_transform(data[numerical_cols])\n",
        "    return data\n",
        "\n",
        "#A1\n",
        "df1 = load_dataset(\"/Lab Session02 Data.xlsx\", \"Purchase Data\")\n",
        "# Segregate data into A (features) and C (target variable)\n",
        "A, C = segregate_data(data)\n",
        "\n",
        "# Print dimensions of matrices A and C\n",
        "dimA, dimC = calculate_dimensions(A, C)\n",
        "print(f\"Dimensionality  of A: {dimA}\")\n",
        "print(f\"Dimensions of C: {dimC}\")\n",
        "\n",
        "# Calculate the rank of matrix A\n",
        "rank = calculate_rank(A)\n",
        "print(f\"Rank of matrix A: {rank}\")\n",
        "\n",
        "#A2\n",
        "# Calculate the pseudo-inverse of A\n",
        "pseudo_inv = calculate_pseudo_inverse(A)\n",
        "print(f\"Pseudo-inverse of A: {pseudo_inv}\")\n",
        "\n",
        "# Calculate the model vector X using pseudo-inverse\n",
        "X = calculate_model_vector(pseudo_inv, C)\n",
        "print(f\"Model vector X: {X}\")\n",
        "\n",
        "#A3\n",
        "# Classify customers as 'RICH' or 'POOR'\n",
        "classes = RichPoorClassifier(data)\n",
        "\n",
        "# Add the classification to the data\n",
        "data = add_class_to_data(data, classes)\n",
        "\n",
        "# Display the final dataframe with class labels\n",
        "print(data[[\"Customer\", \"Candies (#)\", \"Mangoes (Kg)\", \"Milk Packets (#)\", \"Payment (Rs)\", \"Class\"]])\n",
        "\n",
        "#A4\n",
        "df2 = load_dataset(\"/Lab Session02 Data.xlsx\", \"IRCTC Stock Price\")\n",
        "# Statistical calculations\n",
        "print(\"Mean of price:\", calculate_mean(df2, 'Price'))\n",
        "print(\"Variance of price:\", calculate_variance(df2, 'Price'))\n",
        "print(\"Mean price on Wednesdays:\", mean_price_on_wednesday(df2))\n",
        "print(\"Mean price in April:\", mean_price_in_month(df2, \"Apr\"))\n",
        "print(\"Probability of making a loss:\", probability_of_loss(df2))\n",
        "print(\"Probability of making a profit on Wednesday:\", probability_of_profit_on_wednesday(df2))\n",
        "\n",
        "# Plot\n",
        "plot_chg_vs_day(df2)\n",
        "\n",
        "#A5\n",
        "df3 = load_dataset(\"/Lab Session02 Data.xlsx\", \"thyroid0387_UCI\")\n",
        "#Datatypes: Record ID- ,age-ordinal, sex- nominal,on thyroxine- nominal,query on thyroxine, on antithyroid medication - nominal, sick- nominal, pregnant- nominal, thyroid surgery-nominal,I131 treatment-nominal, query hypothyroid-nominal, TSH-Ordinal\n",
        "categorical_cols, numerical_cols = identify_columns(data)\n",
        "# Encode categorical data\n",
        "encoded_data, label_encoders = encode_categorical_data(df3, categorical_cols)\n",
        "print(\"Data after encoding:\")\n",
        "print(encoded_data.head())\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = check_missing_values(encoded_data)\n",
        "if missing_values:\n",
        "    print(\"Missing values:\")\n",
        "    for col, count in missing_values.items():\n",
        "        print(f\"{col}: {count} missing values\")\n",
        "else:\n",
        "    print(\"No missing values\")\n",
        "\n",
        "# Calculate ranges for numerical columns\n",
        "ranges = calculate_ranges(data, numerical_cols)\n",
        "print(\"Ranges for numerical columns:\")\n",
        "for col, col_range in ranges.items():\n",
        "    print(f\"{col}: {col_range}\")\n",
        "\n",
        "# Detect outliers using boxplots\n",
        "outliers = detect_outliers(encoded_data, numerical_cols)\n",
        "if outliers:\n",
        "    print(\"Outliers:\")\n",
        "    for col, outlier_values in outliers.items():\n",
        "        print(f\"{col}: {outlier_values}\")\n",
        "else:\n",
        "    print(\"No outliers detected.\")\n",
        "\n",
        "# Calculate mean and variance for numerical columns\n",
        "stats = calculate_mean_variance(encoded_data, numerical_cols)\n",
        "print(\"Mean and variance of numerical columns:\")\n",
        "for col, values in stats.items():\n",
        "    print(f\"{col}: Mean = {values['mean']}, Variance = {values['variance']}\")\n",
        "\n",
        "#A6\n",
        "# Impute missing values\n",
        "encoded_data = impute_missing_values(encoded_data)\n",
        "print(\"Data after imputation:\")\n",
        "print(encoded_data.head())\n",
        "\n",
        "#A7\n",
        "# Normalize numerical columns\n",
        "data = normalize_data(encoded_data, numerical_cols)\n",
        "print(\"Data after normalization:\")\n",
        "print(data.head())\n",
        "\n",
        "#A8\n",
        "# Similarity Measure (Jaccard Coefficient and SMC)\n",
        "# Selecting the first two observation vectors with binary attributes\n",
        "binary_cols = [col for col in encoded_data.columns if encoded_data[col].nunique() == 2]\n",
        "vec1 = encoded_data.iloc[0][binary_cols].values\n",
        "vec2 = encoded_data.iloc[1][binary_cols].values\n",
        "\n",
        "jc, smc = calculate_jaccard_smc(vec1, vec2)\n",
        "print(f\"Jaccard Coefficient (JC): {jc}\")\n",
        "print(f\"Simple Matching Coefficient (SMC): {smc}\")\n",
        "\n",
        "#A9\n",
        "# Cosine Similarity Measure\n",
        "# Select the first two observation vectors with all attributes\n",
        "vec1_all = encoded_data.iloc[0].values\n",
        "vec2_all = encoded_data.iloc[1].values\n",
        "cosine_sim = calculate_cosine_similarity(vector1_all, vector2_all)\n",
        "print(f\"Cosine Similarity: {cosine_sim}\")\n",
        "\n",
        "#A10\n",
        "# Heatmap Plot\n",
        "plot_similarity_heatmaps(encoded_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wHMRH2QZ4Nqf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}